import os
import streamlit as st
import google.generativeai as genai
from dotenv import load_dotenv
import yaml
import json
import re
import random

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
def load_config(config_path='config.yaml'):
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    """
    try:
        with open(config_path, 'r', encoding='utf-8') as file:
            return yaml.safe_load(file)
    except FileNotFoundError:
        st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« {config_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None
    except yaml.YAMLError as e:
        st.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# è¨­å®šã®èª­ã¿è¾¼ã¿
config = load_config()

# Gemini APIã®è¨­å®š
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
model = genai.GenerativeModel(os.getenv('GEMINI_MODEL'))

def generate_response(prompt):
    """
    Gemini APIã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆ
    """
    try:
        response = model.generate_content(prompt)
        # response.text ãŒç©ºã¾ãŸã¯ç„¡åŠ¹ãªå ´åˆã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ 
        if not response.text.strip():
            st.error("AIã‹ã‚‰ã®å¿œç­”ãŒç©ºã§ã—ãŸã€‚")
            return None
        # print(response.text)
        return response.text
    except Exception as e:
        st.error(f"APIãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def check_colon_format(s: str) -> bool:
    """
    æ–‡å­—åˆ—ãŒã€Œã€‡ã€‡ï¼šâ–³â–³ã€ã®å½¢å¼ã§ã‚ã‚‹ã‹ï¼ˆã€Œï¼šã€ãŒ1ã¤ã§ã€åˆ†å‰²ã™ã‚‹ã¨2ã¤ã®è¦ç´ ã«ãªã‚‹ã‹ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚
    """
    colon_count = s.count('ï¼š')
    if colon_count != 1:
        return False
    parts = s.split('ï¼š')
    if len(parts) == 2 and all(p.strip() for p in parts): # å„éƒ¨åˆ†ãŒç©ºã§ãªã„ã“ã¨ã‚‚ç¢ºèª
        return True
    else:
        return False

def to_full_width_specific(text):
    """
    str.translate() ã‚’ä½¿ã£ã¦ç‰¹å®šã®åŠè§’æ–‡å­—ï¼ˆã‚³ãƒ­ãƒ³ï¼‰ã‚’å…¨è§’ã«å¤‰æ›ã—ã¾ã™ã€‚
    """
    translation_map = str.maketrans(":", "ï¼š")
    return text.translate(translation_map)

def extract_and_parse_json(input_string):
    """
    å…¥åŠ›æ–‡å­—åˆ—ã‹ã‚‰JSONãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã€Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ãƒ‘ãƒ¼ã‚¹ã—ã¾ã™ã€‚
    """
    markdown_match = re.search(r"```json\n(.*?)```", input_string, re.DOTALL)
    
    if markdown_match:
        json_to_parse = markdown_match.group(1).strip()
        # print("--- Markdownã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONã‚’æŠ½å‡ºã—ã¾ã—ãŸ ---")
    else:
        json_to_parse = input_string.strip()
        # print("--- ç´”ç²‹ãªJSONæ–‡å­—åˆ—ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ ---")

    try:
        data = json.loads(json_to_parse)
        return data
    except json.JSONDecodeError as e:
        print(f"ã‚¨ãƒ©ãƒ¼: JSONã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°: {e}")
        return None
    except Exception as e:
        print(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def process_ai_response_and_update_history(response_text):
    """
    AIã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã€å±¥æ­´ã‚’æ›´æ–°ã—ã¾ã™ã€‚
    ç‰©èªã¨é¸æŠè‚¢ã‚’æŠ½å‡ºã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    parsed_output = extract_and_parse_json(response_text)
    
    if parsed_output is None:
        st.error("AIã‹ã‚‰ã®å¿œç­”ãŒJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.session_state.display_choices = False # é¸æŠè‚¢ã¯è¡¨ç¤ºã—ãªã„
        return

    # ç‰©èªéƒ¨åˆ†ã®å‡¦ç†
    story_content = parsed_output.get('ç‰©èª')
    if story_content:
        st.session_state.messages.append({
            'role': 'assistant', 
            'content': story_content
        })
        st.session_state.story += story_content
    else:
        if st.session_state.title == False:
            st.error("AIã®å¿œç­”ã«ã€Œç‰©èªã€ã®ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            st.session_state.display_choices = False
            return

    # é¸æŠè‚¢éƒ¨åˆ†ã®å‡¦ç†
    choices_list = parsed_output.get('é¸æŠè‚¢')
    if choices_list and isinstance(choices_list, list) and len(choices_list) >= 3:
        st.session_state.choices_to_display = choices_list[:3] # æœ€åˆã®3ã¤ã ã‘ã‚’ä¿å­˜
        st.session_state.display_choices = True # é¸æŠè‚¢ã‚’è¡¨ç¤ºã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        if 'climax' not in st.session_state:
            st.session_state.messages.append({
                'role': 'assistant', 
                'content': 'æ¬¡ã®è¡Œå‹•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚'
            })
        else:
            st.session_state.messages.append({
                'role': 'assistant', 
                'content': 'æœ€å¾Œã®è¡Œå‹•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚'
            })
    else:
        if st.session_state.ending == False:
            st.error("AIã®å¿œç­”ã«æœ‰åŠ¹ãªã€Œé¸æŠè‚¢ã€ã®ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.session_state.display_choices = False # é¸æŠè‚¢ã¯è¡¨ç¤ºã—ãªã„
    
    if st.session_state.title:
        title_content = parsed_output.get('title')
        if title_content:
            ending_message = config['message']['ending_message']
            message = ending_message.replace("ï½›ã‚¿ã‚¤ãƒˆãƒ«ï½", title_content)
            st.session_state.messages.append({
                'role': 'assistant', 
                'content': message
            })
        print(title_content)

def one_in_five_chance() -> bool:
    """
    1/5 (20%) ã®ç¢ºç‡ã§ True ã‚’ã€4/5 (80%) ã®ç¢ºç‡ã§ False ã‚’è¿”ã—ã¾ã™ã€‚
    """
    # random.random() ã¯ 0.0 ä»¥ä¸Š 1.0 æœªæº€ã®æµ®å‹•å°æ•°ç‚¹æ•°ã‚’è¿”ã™
    # 0.0 ã‹ã‚‰ 0.2 (æ’ä»–çš„) ã®ç¯„å›²ã§ã‚ã‚Œã° True ã‚’è¿”ã™
    return random.random() < 0.2

def main():
    st.title('ğŸ¤– AIã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒ©ãƒ¼')
    st.write('Gemini APIã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒ©ãƒ¼')


    if not config:
        st.stop() # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ãªã‘ã‚Œã°ã‚¢ãƒ—ãƒªã‚’åœæ­¢

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®åˆæœŸåŒ– ---
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        st.session_state.is_first_load = True
        st.session_state.story = ''
        st.session_state.waiting_for_ai_response = False
        st.session_state.display_choices = False # é¸æŠè‚¢ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹ã®ãƒ•ãƒ©ã‚°
        st.session_state.choices_to_display = [] # è¡¨ç¤ºã™ã‚‹é¸æŠè‚¢ã®ãƒªã‚¹ãƒˆ
        st.session_state.ending = False
        st.session_state.title = False
    
    # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆï¼ˆæœ€åˆã®èª­ã¿è¾¼ã¿æ™‚ã®ã¿ï¼‰
    if st.session_state.is_first_load and config:
        initial_message = config['message']['initial_message']
        st.session_state.messages.append({
            'role': 'assistant', 
            'content': initial_message
        })
        st.session_state.is_first_load = False
        st.rerun() # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«å†å®Ÿè¡Œ

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message['role']):
            st.markdown(message['content'])
    
    # --- AIå¿œç­”ç”Ÿæˆãƒˆãƒªã‚¬ãƒ¼ ---
    # å±¥æ­´ã®æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ã‚‚ã®ã§ã‚ã‚Šã€
    # ã‹ã¤AIãŒç¾åœ¨å¿œç­”ã‚’ç”Ÿæˆä¸­ã§ãªã„å ´åˆ
    if st.session_state.messages and \
       st.session_state.messages[-1]["role"] == "user" and \
       not st.session_state.waiting_for_ai_response:
        
        last_user_message = st.session_state.messages[-1]["content"]
        
        st.session_state.waiting_for_ai_response = True # AIå¿œç­”å¾…ã¡ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        st.session_state.display_choices = False # æ–°ã—ã„AIå¿œç­”ã®ãŸã‚ã«é¸æŠè‚¢ã‚’ãƒªã‚»ãƒƒãƒˆ

        with st.chat_message('assistant'):
            with st.spinner('è€ƒãˆä¸­...'):
                response_text = None
                
                # ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãŒã¾ã å§‹ã¾ã£ã¦ã„ãªã„å ´åˆ (åˆå›å…¥åŠ›æ™‚)
                if not st.session_state.story:
                    if check_colon_format(last_user_message):
                        prompt = config['prompt']['intro_prompt']
                        parts = last_user_message.split('ï¼š')
                        genre = parts[0]
                        theme = parts[1]
                        prompt = prompt.replace("ï½›ã‚¸ãƒ£ãƒ³ãƒ«ï½", genre)
                        prompt = prompt.replace("ï½›ãƒ†ãƒ¼ãƒï½", theme)
                        response_text = generate_response(prompt)
                    else:
                        error_message = config['message']['error_message']['input_error01']
                        st.markdown(error_message)
                        st.session_state.messages.append({
                            'role': 'assistant', 
                            'content': error_message
                        })
                        st.session_state.waiting_for_ai_response = False
                        st.rerun() # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¦UIã‚’æ›´æ–°
                        return # ã“ã“ã§å‡¦ç†ã‚’çµ‚äº†

                else:
                    # ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãŒé€²è¡Œä¸­ã®å ´åˆ (é¸æŠè‚¢ã«ã‚ˆã‚‹å…¥åŠ›æ™‚)
                    # ã“ã“ã§ã€é¸æŠè‚¢ã«å¿œã˜ãŸæ¬¡ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
                    # ä¾‹ï¼šç¾åœ¨ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¨é¸æŠã•ã‚ŒãŸè¡Œå‹•ã‚’AIã«ä¼ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                    # æ³¨æ„: å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯AIã®è¨­è¨ˆã«åˆã‚ã›ã¦èª¿æ•´ã—ã¦ãã ã•ã„
                    if 'climax' not in st.session_state:
                        if one_in_five_chance():
                            prompt = config['prompt']['climax_prompt']
                            st.session_state.climax = True
                        else:
                            prompt = config['prompt']['nomal_prompt']
                    else:
                        prompt = config['prompt']['ending_prompt']
                        st.session_state.ending = True
                    
                    prompt = prompt.replace("ï½›ã“ã‚Œã¾ã§ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ï½", st.session_state.story)
                    prompt = prompt.replace("ï½›ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠï½", last_user_message)
                    # continue_prompt = f"ç¾åœ¨ã®çŠ¶æ³:\n{st.session_state.story}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠ: {last_user_message}\n\nã“ã®é¸æŠã«åŸºã¥ã„ã¦ã€ç‰©èªã®æ¬¡ã®éƒ¨åˆ†ã¨3ã¤ã®æ–°ã—ã„é¸æŠè‚¢ã‚’ä»¥ä¸‹ã®JSONå½¢å¼ã§æä¾›ã—ã¦ãã ã•ã„ã€‚\n```json\n{{\n  \"ç‰©èª\": \"ç‰©èªã®ç¶šãã®ãƒ†ã‚­ã‚¹ãƒˆ\",\n  \"é¸æŠè‚¢\": [\n    \"é¸æŠè‚¢1ã®ãƒ†ã‚­ã‚¹ãƒˆ\",\n    \"é¸æŠè‚¢2ã®ãƒ†ã‚­ã‚¹ãƒˆ\",\n    \"é¸æŠè‚¢3ã®ãƒ†ã‚­ã‚¹ãƒˆ\"\n  ]\n}}\n```"
                    response_text = generate_response(prompt)

            # AIå¿œç­”ã‚’å‡¦ç†ã—ã€å±¥æ­´ã¨é¸æŠè‚¢ã‚’æ›´æ–°
            if response_text:
                process_ai_response_and_update_history(response_text)
            else:
                # AIå¿œç­”ãŒNoneã®å ´åˆï¼ˆAPIã‚¨ãƒ©ãƒ¼ãªã©ï¼‰
                st.session_state.display_choices = False # é¸æŠè‚¢ã¯è¡¨ç¤ºã—ãªã„
            
            if st.session_state.ending:
                st.session_state.title = True
                prompt = config['prompt']['title_prompt']
                prompt = prompt.replace("ï½›ç‰©èªã®å†…å®¹ï½", st.session_state.story)
                response_text = generate_response(prompt)
                process_ai_response_and_update_history(response_text)

            st.session_state.waiting_for_ai_response = False # AIå¿œç­”å¾…ã¡ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.rerun() # AIå¿œç­”ãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰å†åº¦å®Ÿè¡Œã—ã¦UIã‚’æ›´æ–° (ã“ã“ã§é¸æŠè‚¢ã‚‚æç”»ã•ã‚Œã‚‹)

    # --- é¸æŠè‚¢ãƒœã‚¿ãƒ³ã®è¡¨ç¤º ---
    # display_choices ãƒ•ãƒ©ã‚°ãŒTrueã®å ´åˆã®ã¿è¡¨ç¤º
    if st.session_state.display_choices and st.session_state.choices_to_display:
        # st.markdown('æ¬¡ã®è¡Œå‹•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚') # å†è¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚ã€å¿…è¦ã§ã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        cols = st.columns(len(st.session_state.choices_to_display))
        for i, choice in enumerate(st.session_state.choices_to_display):
            with cols[i]:
                if st.button(choice, key=f"choice_button_{i}"):
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
                    st.session_state.messages.append({
                        'role': 'user', 
                        'content': choice
                    })
                    st.session_state.display_choices = False # ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã‚‰é¸æŠè‚¢ã‚’ä¸€æ™‚çš„ã«éè¡¨ç¤º
                    st.session_state.choices_to_display = [] # é¸æŠè‚¢ã‚’ã‚¯ãƒªã‚¢
                    st.rerun() # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰å†å®Ÿè¡Œã—ã¦è¡¨ç¤ºã‚’æ›´æ–°


    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    # AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­ã®å ´åˆã¯ç„¡åŠ¹ã«ã™ã‚‹
    if not st.session_state.waiting_for_ai_response:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã€‚æ‰‹å‹•ã§å…¥åŠ›ã•ã‚ŒãŸå ´åˆã®ã¿ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã«å…¥ã‚‹
        user_input_from_chat_input = st.chat_input('ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„', key="chat_input", disabled=st.session_state.ending)
        if user_input_from_chat_input:
            user_input_from_chat_input = to_full_width_specific(user_input_from_chat_input)
            # æ‰‹å‹•ã§å…¥åŠ›ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
            st.session_state.messages.append({
                'role': 'user', 
                'content': user_input_from_chat_input
            })
            # UIã«æ‰‹å‹•å…¥åŠ›ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º (chat_messageã§è¡¨ç¤ºã•ã‚Œã‚‹ã®ã§é€šå¸¸ã¯ä¸è¦ã ãŒã€å³æ™‚æ€§ã‚’æ±‚ã‚ã‚‹ãªã‚‰)
            # with st.chat_message('user'):
            #     st.markdown(user_input_from_chat_input)
            st.rerun() # æ–°ã—ã„å…¥åŠ›ãŒã‚ã£ãŸã‚‰å†å®Ÿè¡Œã—ã¦AIå¿œç­”ã‚’ãƒˆãƒªã‚¬ãƒ¼

if __name__ == '__main__':
    main()